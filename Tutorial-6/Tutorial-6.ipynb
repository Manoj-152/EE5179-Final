{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BrUVXuMSkDQQ"
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "A9EtAGtyTQJ8"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import sys\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h_AuUCJJkRiD"
   },
   "source": [
    "## Utilising GPU using Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ERUEzqqakS3e",
    "outputId": "f1a065db-0fbc-411a-be98-96e417bfd33c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "# cpu-gpu\n",
    "a = torch.randn((3, 4))\n",
    "print(a.device)\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "a = a.to(device)\n",
    "print(a.device)\n",
    "\n",
    "# a more generic code\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n474i7A4kjm3",
    "outputId": "c9334499-998f-48e5-a3ab-164346ddc520"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Sep 14 16:01:20 2022       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 510.73.05    Driver Version: 510.73.05    CUDA Version: 11.6     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  NVIDIA GeForce ...  Off  | 00000000:05:00.0  On |                  N/A |\r\n",
      "| 59%   53C    P2    99W / 370W |   3794MiB / 10240MiB |     19%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|    0   N/A  N/A      1104      G   /usr/lib/xorg/Xorg                 41MiB |\r\n",
      "|    0   N/A  N/A     55444      G   /usr/lib/xorg/Xorg                243MiB |\r\n",
      "|    0   N/A  N/A     55567      G   /usr/bin/gnome-shell               32MiB |\r\n",
      "|    0   N/A  N/A     73761      G   ...603286121342559762,131072       18MiB |\r\n",
      "|    0   N/A  N/A    104353      G   gzclient                           83MiB |\r\n",
      "|    0   N/A  N/A    104365      G   gzserver                            7MiB |\r\n",
      "|    0   N/A  N/A    108549      C   /usr/bin/python3                 1705MiB |\r\n",
      "|    0   N/A  N/A    112308      C   /usr/bin/python3                 1643MiB |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NxjZWEfIkn7X"
   },
   "source": [
    "## Dataset and Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 101,
     "referenced_widgets": [
      "26fa1345d7874f65908baacf637b44df",
      "d1d1b169249b45bf821ac6da3cb8a0b1",
      "685ad53540ab4c0aa0d24f7fe46c4362",
      "d632174679ca4f5ca60f0fd9808b5904",
      "3dbfc107a8144247be99e87c85aa7482",
      "c41c44ba515e4db09c3198a82abb8732",
      "d3499a4d309d4e489d25ab795f379ae6",
      "db0e28a49e644d90bf0cdbc2731341a4",
      "06207f42aceb4a8b8d0137af9022f4c3",
      "640fc0583bd644a0bbe30c90eaa8326a",
      "080d88887c78489e8351298ca4128f8d"
     ]
    },
    "id": "Afh2_n-PTc_U",
    "outputId": "e76c6d52-e2d6-45ef-90b6-480f20a6ebe6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_transform = transforms.Compose([\n",
    "  transforms.RandomCrop(32, padding=4),\n",
    "  transforms.RandomHorizontalFlip(),\n",
    "  transforms.ToTensor(),\n",
    "  transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "test_transform = transforms.Compose([\n",
    "  transforms.ToTensor(),\n",
    "  transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "train_dset = torchvision.datasets.CIFAR10(root=\"data/\", train=True, transform=train_transform, download=True)\n",
    "test_dset = torchvision.datasets.CIFAR10(root=\"data/\", train=False, transform=test_transform, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rwrVIg6BUUKI",
    "outputId": "d2e5bfef-c9fa-46e6-b314-5c345ec3e070"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of train samples: 50000\n",
      "# of test samples: 10000\n"
     ]
    }
   ],
   "source": [
    "print(f\"# of train samples: {len(train_dset)}\")\n",
    "print(f\"# of test samples: {len(test_dset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "R_RniHmyUgsz"
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dset, batch_size=100, shuffle=True, num_workers=2)\n",
    "test_loader = DataLoader(test_dset, batch_size=100, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4GoIkiN8VJXx",
    "outputId": "08387a74-b9fb-4905-e7f1-31a5666e8ff4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of train batches: 500\n",
      "# of test batches: 100\n"
     ]
    }
   ],
   "source": [
    "print(f\"# of train batches: {len(train_loader)}\")\n",
    "print(f\"# of test batches: {len(test_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uokKboX4VO02",
    "outputId": "2e320992-7e84-4c3c-a5d5-8d2d19c8fb7f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample i/o sizes\n",
      "input size: torch.Size([100, 3, 32, 32])\n",
      "output size: torch.Size([100])\n"
     ]
    }
   ],
   "source": [
    "print(\"sample i/o sizes\")\n",
    "data = next(iter(train_loader))\n",
    "img, target = data\n",
    "print(f\"input size: {img.shape}\")\n",
    "print(f\"output size: {target.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JSJjyNdKkr1t"
   },
   "source": [
    "## LeNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Usjem5RSVdso"
   },
   "outputs": [],
   "source": [
    "class LeNet(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(LeNet, self).__init__()\n",
    "    self.conv1 = nn.Conv2d(3, 6, kernel_size=5)\n",
    "    self.conv2 = nn.Conv2d(6, 16, kernel_size=5)\n",
    "    # TODO: missing input feature size\n",
    "    self.fc1   = nn.Linear(None, 120)\n",
    "    self.fc2   = nn.Linear(120, 84)\n",
    "    # TODO: missing output feature size\n",
    "    self.fc3   = nn.Linear(84, None)\n",
    "    self.activ = nn.ReLU()\n",
    "\n",
    "  # TODO: add maxpool operation of given kernel size\n",
    "  # https://pytorch.org/docs/stable/nn.functional.html\n",
    "  def pool(self, x, kernel_size=2):\n",
    "    out = None\n",
    "    return out\n",
    "\n",
    "  def forward(self, x):\n",
    "    out = self.activ(self.conv1(x))\n",
    "    out = self.pool(out)\n",
    "    out = self.activ(self.conv2(out))\n",
    "    out = self.pool(out)\n",
    "\n",
    "    # TODO: flatten\n",
    "    out = None\n",
    "    out = self.activ(self.fc1(out))\n",
    "    out = self.activ(self.fc2(out))\n",
    "    out = self.fc3(out)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yJAne7Wfkuvr"
   },
   "source": [
    "## VGG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rDgBFjcgXxqC"
   },
   "outputs": [],
   "source": [
    "class VGG(nn.Module):\n",
    "  CONFIGS = {\n",
    "      \"vgg11\": [64, \"pool\", 128, \"pool\", 256, 256, \"pool\", 512, 512, \"pool\", 512, 512, \"pool\"],\n",
    "      \"vgg13\": [64, 64, \"pool\", 128, 128, \"pool\", 256, 256, \"pool\", 512, 512, \"pool\", 512, 512, \"pool\"],\n",
    "      \"vgg16\": [64, 64, \"pool\", 128, 128, \"pool\", 256, 256, 256, \"pool\", 512, 512, 512, \"pool\", 512, 512, 512, \"pool\"],\n",
    "      \"vgg19\": [64, 64, \"pool\", 128, 128, \"pool\", 256, 256, 256, 256, \"pool\", 512, 512, 512, 512, \"pool\", 512, 512, 512, 512, \"pool\"],\n",
    "  }\n",
    "  def __init__(self, cfg):\n",
    "    super(VGG, self).__init__()\n",
    "    # TODO: missing input dimension\n",
    "    in_dim = None\n",
    "    layers = []\n",
    "    for layer in self.CONFIGS[cfg]:\n",
    "        if layer == \"pool\":\n",
    "            # TODO: add maxpool module of given kernel size, stride (here 2 each)\n",
    "            # https://pytorch.org/docs/stable/nn.html\n",
    "            maxpool = None\n",
    "            layers.append(maxpool)\n",
    "        else:\n",
    "            # TODO: add sequential module consisting of convolution (kernel size = 3, padding = 1), batchnorm, relu\n",
    "            # https://pytorch.org/docs/stable/generated/torch.nn.Sequential.html?highlight=sequential#torch.nn.Sequential\n",
    "            block = None\n",
    "            layers.append(block)\n",
    "            in_dim = layer\n",
    "    # TODO: add average pool to collapse spatial dimensions\n",
    "    avgpool = None\n",
    "    layers.append(avgpool)\n",
    "    self.layers = nn.Sequential(*layers)\n",
    "    # TODO: missing output features\n",
    "    self.fc = nn.Linear(512, None)\n",
    "\n",
    "  def forward(self, x):\n",
    "    out = self.layers(x)\n",
    "    # TODO: flatten\n",
    "    out = None\n",
    "    out = self.fc(out)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gRtGz0Z_kwJr"
   },
   "source": [
    "## ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HwEtA8o0bRnz"
   },
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "  expansion = 1\n",
    "\n",
    "  def __init__(self, in_dim, dim, stride=1):\n",
    "    super(BasicBlock, self).__init__()\n",
    "    self.conv1 = nn.Conv2d(in_dim, dim, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "    self.bn1 = nn.BatchNorm2d(dim)\n",
    "    self.conv2 = nn.Conv2d(dim, dim, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "    self.bn2 = nn.BatchNorm2d(dim)\n",
    "    self.activ = nn.ReLU()\n",
    "\n",
    "    self.shortcut = nn.Identity()\n",
    "    # TODO: missing condition for parameterized shortcut connection (hint: when input and output dimensions don't match - both spatial, feature)\n",
    "    if (None):\n",
    "        # TODO: add sequential module consisting of 1x1 convolution (given stride, bias=False), batchnorm\n",
    "        self.shortcut = None\n",
    "      \n",
    "  def forward(self, x):\n",
    "    out = self.activ(self.bn1(self.conv1(x)))\n",
    "    out = self.bn2(self.conv2(out))\n",
    "    # TODO: missing residual connection\n",
    "    out = None\n",
    "    out = self.activ(out)\n",
    "    return out\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "  expansion = 4\n",
    "\n",
    "  def __init__(self, in_dim, dim, stride=1):\n",
    "    super(Bottleneck, self).__init__()\n",
    "    self.conv1 = nn.Conv2d(in_dim, dim, kernel_size=1, bias=False)\n",
    "    self.bn1 = nn.BatchNorm2d(dim)\n",
    "    self.conv2 = nn.Conv2d(dim, dim, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "    self.bn2 = nn.BatchNorm2d(dim)\n",
    "    self.conv3 = nn.Conv2d(dim, self.expansion * dim, kernel_size=1, bias=False)\n",
    "    self.bn3 = nn.BatchNorm2d(self.expansion*dim)\n",
    "    self.activ = nn.ReLU()\n",
    "\n",
    "    self.shortcut = nn.Identity()\n",
    "    # TODO: missing condition for parameterized shortcut connection (hint: when input and output dimensions don't match - both spatial, feature)\n",
    "    if (None):\n",
    "        # TODO: add sequential module consisting of 1x1 convolution (given stride, bias=False), batchnorm\n",
    "        self.shortcut = None\n",
    "\n",
    "  def forward(self, x):\n",
    "    out = self.activ(self.bn1(self.conv1(x)))\n",
    "    out = self.activ(self.bn2(self.conv2(out)))\n",
    "    out = self.bn3(self.conv3(out))\n",
    "    # TODO: missing residual connection\n",
    "    out = None\n",
    "    out = self.activ(out)\n",
    "    return out\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "  CONFIGS = {\n",
    "      \"resnet18\": (BasicBlock, [2, 2, 2, 2]),\n",
    "      \"resnet34\": (BasicBlock, [3, 4, 6, 3]),\n",
    "      \"resnet50\": (Bottleneck, [3, 4, 6, 3]),\n",
    "      \"resnet101\": (Bottleneck, [3, 4, 23, 3]),\n",
    "      \"resnet152\": (Bottleneck, [3, 8, 36, 3]),\n",
    "  }\n",
    "  def __init__(self, cfg):\n",
    "    super(ResNet, self).__init__()\n",
    "    block, num_blocks = self.CONFIGS[cfg]\n",
    "    self.in_dim = 64\n",
    "    self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "    self.bn1 = nn.BatchNorm2d(64)\n",
    "    self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
    "    self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
    "    self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
    "    self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
    "    self.activ = nn.ReLU()\n",
    "    # TODO: missing output features\n",
    "    self.linear = nn.Linear(512*block.expansion, None)\n",
    "\n",
    "  def _make_layer(self, block, dim, num_blocks, stride):\n",
    "    strides = [stride] + [1]*(num_blocks-1)    \n",
    "    layers = []\n",
    "    for stride in strides: \n",
    "        # TODO: create layers within block\n",
    "        layer = None\n",
    "        layers.append(layer)\n",
    "        # TODO: update in_dim based on block output size\n",
    "        self.in_dim = None\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "  def forward(self, x):\n",
    "    out = self.activ(self.bn1(self.conv1(x)))\n",
    "    out = self.layer1(out)\n",
    "    out = self.layer2(out)\n",
    "    out = self.layer3(out)\n",
    "    out = self.layer4(out)\n",
    "    # TODO: average pool and flatten\n",
    "    out = None\n",
    "    out = self.linear(out)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K4ywUDe3k0ZQ"
   },
   "source": [
    "## Utility functions (can ignore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iUXIGxAvfdBc"
   },
   "outputs": [],
   "source": [
    "def pbar(p=0, msg=\"\", bar_len=20):\n",
    "    sys.stdout.write(\"\\033[K\")\n",
    "    sys.stdout.write(\"\\x1b[2K\" + \"\\r\")\n",
    "    block = int(round(bar_len * p))\n",
    "    text = \"Progress: [{}] {}% {}\".format(\n",
    "        \"\\x1b[32m\" + \"=\" * (block - 1) + \">\" + \"\\033[0m\" + \"-\" * (bar_len - block),\n",
    "        round(p * 100, 2),\n",
    "        msg,\n",
    "    )\n",
    "    print(text, end=\"\\r\")\n",
    "    if p == 1:\n",
    "        print()\n",
    "\n",
    "\n",
    "class AvgMeter:\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.metrics = {}\n",
    "\n",
    "    def add(self, batch_metrics):\n",
    "        if self.metrics == {}:\n",
    "            for key, value in batch_metrics.items():\n",
    "                self.metrics[key] = [value]\n",
    "        else:\n",
    "            for key, value in batch_metrics.items():\n",
    "                self.metrics[key].append(value)\n",
    "\n",
    "    def get(self):\n",
    "        return {key: np.mean(value) for key, value in self.metrics.items()}\n",
    "\n",
    "    def msg(self):\n",
    "        avg_metrics = {key: np.mean(value) for key, value in self.metrics.items()}\n",
    "        return \"\".join([\"[{}] {:.5f} \".format(key, value) for key, value in avg_metrics.items()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cM4qJwaDlBwD"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XdwembsSja6-"
   },
   "outputs": [],
   "source": [
    "def train(model, optim, lr_sched=None, epochs=200, device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"), criterion=None, metric_meter=None, out_dir=\"out/\"):\n",
    "  model.to(device)\n",
    "  best_acc = 0\n",
    "  for epoch in range(epochs):\n",
    "    model.train()\n",
    "    metric_meter.reset()\n",
    "    for indx, (img, target) in enumerate(train_loader):\n",
    "      # TODO: send to device (cpu or gpu)\n",
    "      img = None\n",
    "      target = None\n",
    "\n",
    "      # TODO: missing forward pass\n",
    "      out = None\n",
    "      loss = criterion(out, target)\n",
    "      # TODO: missing backward, parameter update\n",
    "\n",
    "      metric_meter.add({\"train loss\": loss.item()})\n",
    "      pbar(indx / len(train_loader), msg=metric_meter.msg())\n",
    "    pbar(1, msg=metric_meter.msg())\n",
    "\n",
    "    model.eval()\n",
    "    metric_meter.reset()\n",
    "    for indx, (img, target) in enumerate(test_loader):\n",
    "      # TODO: send to device (cpu or gpu)\n",
    "      img = None\n",
    "      target = None\n",
    "\n",
    "      # TODO: missing forward pass\n",
    "      out = None\n",
    "      loss = criterion(out, target)\n",
    "      # TODO: compute accuracy\n",
    "      acc = None\n",
    "\n",
    "      metric_meter.add({\"test loss\": loss.item(), \"test acc\": acc})\n",
    "      pbar(indx / len(test_loader), msg=metric_meter.msg())\n",
    "    pbar(1, msg=metric_meter.msg())\n",
    "    \n",
    "    test_metrics = metric_meter.get()\n",
    "    if test_metrics[\"test acc\"] > best_acc:\n",
    "      print(\n",
    "          \"\\x1b[33m\"\n",
    "          + f\"test acc improved from {round(best_acc, 5)} to {round(test_metrics['test acc'], 5)}\"\n",
    "          + \"\\033[0m\"\n",
    "      )\n",
    "      best_acc = test_metrics['test acc']\n",
    "      torch.save(model.state_dict(), os.path.join(out_dir, \"best.ckpt\"))\n",
    "    lr_sched.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7QSyZus3lD7f"
   },
   "source": [
    "## Run Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1Wy8hIQfiGqS"
   },
   "outputs": [],
   "source": [
    "def run_experiment(model_name=\"lenet\", model_cfg=None, epochs=200):\n",
    "  if model_name == \"lenet\":\n",
    "    model = LeNet()\n",
    "  elif model_name == \"vgg\":\n",
    "    model = VGG(model_cfg)\n",
    "  elif model_name == \"resnet\":\n",
    "    model = ResNet(model_cfg)\n",
    "  else:\n",
    "    raise NotImplementedError()\n",
    "  optim = torch.optim.SGD(model.parameters(), lr=1e-1, momentum=0.9, weight_decay=5e-4)\n",
    "  lr_sched = torch.optim.lr_scheduler.CosineAnnealingLR(optim, T_max=epochs)\n",
    "  criterion = nn.CrossEntropyLoss()\n",
    "  metric_meter = AvgMeter()\n",
    "  out_dir = f\"{model_name}_{model_cfg}\"\n",
    "  os.makedirs(out_dir, exist_ok=True)\n",
    "  train(model, optim, lr_sched, epochs=epochs, criterion=criterion, metric_meter=metric_meter, out_dir=out_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 364
    },
    "id": "jgYPvSM4jUEH",
    "outputId": "d7b9ddf7-beb6-4b8b-f078-30526c717a04"
   },
   "outputs": [],
   "source": [
    "run_experiment(model_name=\"lenet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4HBcgGTHlQqx"
   },
   "source": [
    "## Questions\n",
    "- Train and report test set metrics on three model types - LeNet, VGG, ResNet. \n",
    "- Which model performs the best and why?\n",
    "- Which model performs the worst and why?\n",
    "- BONUS (extra marks): Modify the LeNet model's convolution layers and compare performance against number of layers (depth), number of nodes per layer (width). (Require atleast 3 data points each for width and depth). Feel free to reduce the number of epochs to obtain results quickly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Jaf-PO1-l6c3"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "06207f42aceb4a8b8d0137af9022f4c3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "080d88887c78489e8351298ca4128f8d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "26fa1345d7874f65908baacf637b44df": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d1d1b169249b45bf821ac6da3cb8a0b1",
       "IPY_MODEL_685ad53540ab4c0aa0d24f7fe46c4362",
       "IPY_MODEL_d632174679ca4f5ca60f0fd9808b5904"
      ],
      "layout": "IPY_MODEL_3dbfc107a8144247be99e87c85aa7482"
     }
    },
    "3dbfc107a8144247be99e87c85aa7482": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "640fc0583bd644a0bbe30c90eaa8326a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "685ad53540ab4c0aa0d24f7fe46c4362": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_db0e28a49e644d90bf0cdbc2731341a4",
      "max": 170498071,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_06207f42aceb4a8b8d0137af9022f4c3",
      "value": 170498071
     }
    },
    "c41c44ba515e4db09c3198a82abb8732": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d1d1b169249b45bf821ac6da3cb8a0b1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c41c44ba515e4db09c3198a82abb8732",
      "placeholder": "​",
      "style": "IPY_MODEL_d3499a4d309d4e489d25ab795f379ae6",
      "value": "100%"
     }
    },
    "d3499a4d309d4e489d25ab795f379ae6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d632174679ca4f5ca60f0fd9808b5904": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_640fc0583bd644a0bbe30c90eaa8326a",
      "placeholder": "​",
      "style": "IPY_MODEL_080d88887c78489e8351298ca4128f8d",
      "value": " 170498071/170498071 [00:14&lt;00:00, 12540841.25it/s]"
     }
    },
    "db0e28a49e644d90bf0cdbc2731341a4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
